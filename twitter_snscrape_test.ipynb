{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import snscrape\n",
    "from snscrape.modules.twitter import TwitterSearchScraper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect('./dataset/dataset_db.db')\n",
    "cur = con.cursor()\n",
    "cur.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS tweet (\n",
    "                    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    url             TEXT NOT NULL,\n",
    "                    date            TEXT NOT NULL,\n",
    "                    like_count      INTEGER NOT NULL,\n",
    "                    reply_count     INTEGER NOT NULL,\n",
    "                    retweet_count   INTEGER NOT NULL\n",
    "            );''')\n",
    "cur.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS tweet_media (\n",
    "                    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    tweet_id        INTEGER NOT NULL,\n",
    "                    type            TEXT NOT NULL,\n",
    "                    url             TEXT NOT NULL\n",
    "            );''')\n",
    "cur.execute('''\n",
    "                CREATE TABLE IF NOT EXISTS media (\n",
    "                    id              INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                    url             TEXT NOT NULL,\n",
    "                    model           TEXT NOT NULL,    \n",
    "                    status          TEXT,\n",
    "                    media_type      TEXT NOT NULL,\n",
    "                    source          TEXT NOT NULL\n",
    "            );''')\n",
    "\n",
    "def insert_into_table(db: str, table_name: str, data: list, return_rowid: bool):\n",
    "    con = sqlite3.connect(db)\n",
    "    cur = con.cursor()\n",
    "    \n",
    "    sql = f\"INSERT OR IGNORE INTO {table_name} VALUES ({','.join(['?' for _ in data[0]])})\"\n",
    "    cur.executemany(sql, data)\n",
    "    \n",
    "    if return_rowid:\n",
    "        cur.execute(f\"SELECT MAX(id) FROM {table_name}\")\n",
    "        result = cur.fetchone()\n",
    "        last_rowid = result[0]\n",
    "        con.commit()\n",
    "        con.close()\n",
    "        return last_rowid\n",
    "\n",
    "    con.commit()\n",
    "    con.close()\n",
    "\n",
    "def update_table(db: str, table_name: str, set_values_dict: dict, where_clause: str):\n",
    "    con = sqlite3.connect(db)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    set_clause = ', '.join([f\"{col} = ?\" for col in set_values_dict.keys()])\n",
    "    sql = f\"UPDATE {table_name} SET {set_clause} WHERE {where_clause}\"\n",
    "    cur.execute(sql, tuple(set_values_dict.values()))\n",
    "\n",
    "    con.commit()\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "tweet_list = []\n",
    "for i,tweet in enumerate(sntwitter.TwitterUserScraper('IgnacioBusso').get_items()):\n",
    "    if i>50:\n",
    "        break\n",
    "    # print(vars(tweet))\n",
    "    if tweet.media:\n",
    "        print(tweet.media)\n",
    "\n",
    "    # tweet_list.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "def get_specific_tweet(tweet_id):\n",
    "    print(tweet_id)\n",
    "    tweets_list = []\n",
    "    # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    " \n",
    "    for i,tweet in enumerate(sntwitter.TwitterTweetScraper(tweetId=1656853595352883202,mode=sntwitter.TwitterTweetScraperMode.SINGLE).get_items()):\n",
    "        # print(tweet)\n",
    "        # print(tweet.rawContent)\n",
    "        # print(vars(tweet))\n",
    "        print(tweet.media)\n",
    "        print(tweet.media[0])\n",
    "        print(tweet.media[0].fullUrl)\n",
    "        # print(type(tweet.media))\n",
    "        # print(type(tweet.media[0]))\n",
    "get_specific_tweet(1656853595352883202)\n",
    "\n",
    "# GALLERY, 4 IMAGES: \n",
    "#       https://twitter.com/TheGreyPatriot_/status/1657313944317427713\n",
    "#       https://twitter.com/PucaraD/status/1657009349489770496\n",
    "# 1 IMAGE            \n",
    "#       1656853595352883202\n",
    "# VIDEO              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vehicle_list = [  # (model, query content)\n",
    "    # ('M113', 'M113'),\n",
    "    # ('MT-LB','MT-LB OR MT-LBV OR MT-LBVM OR MT-LBVMK OR MT-LBVM/K OR MT-LBu'),\n",
    "    # ('BTR-80','BTR-80 OR BTR-82'),\n",
    "    # ('BTR-82A','BTR-80A OR BTR-82A'),\n",
    "    # ('BMP-1','BMP-1'),\n",
    "    # ('BMP-2','BMP-2 OR BMP-2M'),\n",
    "    # ('BMP-3','BMP-3 OR BMP-3M'),\n",
    "    # ('T-62','T-62 OR T-62M OR T-62MV'),\n",
    "    # ('T-64','T-64 OR T-64A OR T-64B OR T-64BV OR T-64B1M OR T-64BM OR T-64BM2'),\n",
    "    ('T-72','T-72 OR T-72A OR T-72AV OR T-72AMT OR T-72B OR T-72BA OR T-72B3 OR T-72B3 OR T-72M OR T-72M1'),\n",
    "    # ('T-80','T-80 OR T-80B OR T-80BV OR T-80U OR T-80BVM'),\n",
    "    # ('T-90','T-90 OR T-90A OR T-90M'),\n",
    "    # ('2S1','2S1 OR Gvozdika'),\n",
    "    # ('2S3','2S3 OR Akatsiya'),\n",
    "    # ('2S19','2S19 OR 2S19M OR 2S19M1 OR 2S19M2 OR Msta OR Msta-S OR Msta-SM2'),\n",
    "    # ('BM-21','BM-21'),\n",
    "]\n",
    "\n",
    "query_terms_list = [\n",
    "    'russian', \n",
    "    'ukrainian', \n",
    "    # 'russia', \n",
    "    # 'ukraine', \n",
    "    # 'DNR', \n",
    "    # 'DPR', \n",
    "    # 'LNR', \n",
    "    # 'LPR', \n",
    "    # 'captured', \n",
    "    # 'abandoned', \n",
    "    # 'damaged', \n",
    "    # 'destroyed', \n",
    "    # 'kherson', \n",
    "    # 'kharkiv', \n",
    "    # 'donetsk', \n",
    "    # 'severodonetsk', \n",
    "    # 'luhansk', \n",
    "    # 'lugansk', \n",
    "    # 'donbass',\n",
    "    # 'Dnieper', \n",
    "    # 'Dnipro', \n",
    "    # 'izium', \n",
    "    # 'izyum ',\n",
    "    # 'bakhmut', \n",
    "    # 'offensive', \n",
    "    # 'attack', \n",
    "    # 'repulsed'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "query = '(T-90 ukraine ukranian) filter:links lang:en'\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "    print(tweet.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "\n",
    "date_since = '2022-02-23'\n",
    "date_until = '2023-02-25'\n",
    "vehicle_type = 'T-72'\n",
    "filters = 'filter:videos lang:en'\n",
    "\n",
    "# url_counter = 0\n",
    "# url_list = []\n",
    "# url_list = read_list(vehicle_type)\n",
    "\n",
    "for term in query_terms_list:\n",
    "    query = f'{vehicle_type} {term} since:{date_since} until:{date_until} {filters}'\n",
    "    print(query)\n",
    "    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n",
    "        if tweet.media:\n",
    "            tweet_data = [None, tweet.url, str(tweet.date).split('+')[0], tweet.likeCount, tweet.replyCount, tweet.retweetCount]\n",
    "            last_rowid = insert_into_table('./dataset/dataset_db.db', 'tweet', [tweet_data], True)\n",
    "            for medium in tweet.media:\n",
    "                if isinstance(medium, sntwitter.Photo):\n",
    "                    pass\n",
    "                    # Add to tweet_media table\n",
    "                    image_url = medium.fullUrl.replace('?format=', '.', 1).rsplit('&', 1)[0]\n",
    "                    media_data = [None, last_rowid, 'image', image_url]\n",
    "                    insert_into_table('./dataset/dataset_db.db', 'tweet_media', [media_data], False)\n",
    "\n",
    "                    # Add to JSON files\n",
    "                    # url_list.append([image_url,'unknown','image','twitter'])\n",
    "                elif isinstance(medium, sntwitter.Video):\n",
    "\n",
    "                    # Filter out variants 'video' in its content type\n",
    "                    video_list = [variant for variant in medium.variants if 'video' in str(variant.contentType)]\n",
    "\n",
    "                    # Sort the videos by bitrate (descending order)\n",
    "                    sorted_video_list = sorted(video_list, key=lambda v: v.bitrate, reverse=True)\n",
    "\n",
    "                    # Get the URL of the variant with the highest bitrate\n",
    "                    if sorted_video_list:\n",
    "                        video_url = sorted_video_list[0].url\n",
    "                    else:\n",
    "                        video_url = None\n",
    "\n",
    "                    # Add to tweet_media table\n",
    "                    media_data = [None, last_rowid, 'video', video_url]\n",
    "                    insert_into_table('./dataset/dataset_db.db', 'tweet_media', [media_data], False)\n",
    "\n",
    "                    # Add to JSON files\n",
    "                    # url_list.append([video_url,'unknown','image','twitter'])\n",
    "                elif isinstance(medium, sntwitter.Gif):\n",
    "                    # print(medium.variants[0].url)\n",
    "                    pass\n",
    "                else:\n",
    "                    # print(medium.variants[0].url)\n",
    "                    pass\n",
    "\n",
    "                        \n",
    "                    # elif 'twitter.com/'  in item.url:\n",
    "\n",
    "\n",
    "        # print(tweet.url)\n",
    "        # try:\n",
    "        #     media = tweet.media[0].fullUrl # .previewUrl if you want previewUrl\n",
    "        #     print(media)\n",
    "        # except:\n",
    "        #     media = tweet.media # or None or '' or any default value \n",
    "        #     print(media)\n",
    "\n",
    " \n",
    "query = 'T-72 filter:images since:2022-02-23 until:2022-12-31' \n",
    "# since:2023-01-01 until:2023-02-01' lang:es \n",
    "# filter:image filter:images filter:videos filter:links filter:media \n",
    "\n",
    "print(query)\n",
    "\n",
    "# query = 'gm filter:videos lang:en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in cur.execute(\"SELECT * FROM tweet\"):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in cur.execute(\"SELECT * FROM tweet_media\"):\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for medium in tweet.media:\n",
    "# \tif medium.type == 'photo':\n",
    "# \t\t# Do something with medium.fullUrl\n",
    "# \telif medium.type == 'video':\n",
    "# \t\t# Do something with one of the URLs in medium.variants\n",
    "\n",
    "# if tweet.media:\n",
    "#     for medium in tweet.media:\n",
    "#         if isinstance(medium, snscrape.modules.twitter.Photo):\n",
    "#             print(medium.fullUrl.rsplit('=', 1)[0] + '=orig')  # Replace =large with =orig\n",
    "#         elif isinstance(medium, (snscrape.modules.twitter.Video, snscrape.modules.twitter.Gif)):\n",
    "#             # do something with medium.variants, I guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIDEO MEDIUM FORMAT\n",
    "# Video(\n",
    "# \tthumbnailUrl='https://pbs.twimg.com/ext_tw_video_thumb/1496897376707129345/pu/img/1xIC4FYQ6nhQT5iF.jpg', \n",
    "# \tvariants=[\n",
    "# \t\tVideoVariant(url='https://video.twimg.com/ext_tw_video/1496897376707129345/pu/vid/480x854/LO7Dab3-krcbozuE.mp4?tag=12', contentType='video/mp4', bitrate=950000), \n",
    "# \t\tVideoVariant(url='https://video.twimg.com/ext_tw_video/1496897376707129345/pu/pl/G_rCkEGupzECbXvF.m3u8?tag=12&container=fmp4', contentType='application/x-mpegURL', bitrate=None), \n",
    "# \t\tVideoVariant(url='https://video.twimg.com/ext_tw_video/1496897376707129345/pu/vid/320x568/xXfRvaSVqoPE_WNy.mp4?tag=12', contentType='video/mp4', bitrate=632000)], \n",
    "# \tduration=23.798, \n",
    "# \tviews=50, altText=None)\n",
    "\n",
    "\n",
    "\n",
    "# Video(\n",
    "# \tthumbnailUrl='https://pbs.twimg.com/ext_tw_video_thumb/1496897160935358466/pu/img/-zqKLLzc10jZWxHL.jpg', \n",
    "# \tvariants=[\n",
    "# \t\tVideoVariant(url='https://video.twimg.com/ext_tw_video/1496897160935358466/pu/vid/592x1280/83ZS6AHbqiB-4VY0.mp4?tag=12', contentType='video/mp4', bitrate=2176000), \n",
    "# \t\tVideoVariant(url='https://video.twimg.com/ext_tw_video/1496897160935358466/pu/vid/480x1036/c4ptH8swrfVHKOPv.mp4?tag=12', contentType='video/mp4', bitrate=950000), \n",
    "# \t\tVideoVariant(url='https://video.twimg.com/ext_tw_video/1496897160935358466/pu/vid/320x690/en8hFf9jSDIW-kET.mp4?tag=12', contentType='video/mp4', bitrate=632000), \n",
    "# \t\tVideoVariant(url='https://video.twimg.com/ext_tw_video/1496897160935358466/pu/pl/7p64JbsupNsijgRT.m3u8?tag=12&container=fmp4', contentType='application/x-mpegURL', bitrate=None)], \n",
    "# \tduration=11.261, \n",
    "# \tviews=450, \n",
    "# \taltText=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweet_list:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper = TwitterSearchScraper(query)\n",
    "\n",
    "result = []\n",
    "\n",
    "for i, item in enumerate(scraper.get_items()):\n",
    "        result.append(item)\n",
    "        # print(tweet.media)\n",
    "        # print(tweet.media[0].fullUrl)\n",
    "        try:\n",
    "            media = tweet.media[0].fullUrl # .previewUrl if you want previewUrl\n",
    "            print(media)\n",
    "        except:\n",
    "            media = tweet.media # or None or '' or any default value \n",
    "            print(media)\n",
    "        if i == 100:\n",
    "                break\n",
    "        \n",
    "print(len(result))\n",
    "for i in result:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
