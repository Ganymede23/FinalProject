{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0630aa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from twitter_authentication import API_KEY, API_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET, BEARER_TOKEN\n",
    "import json\n",
    "\n",
    "# V1 AUTH\n",
    "#auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "#auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "#tweepy.Client(bearer_token=BEARER_TOKEN, consumer_key=API_KEY, consumer_secret=API_SECRET, access_token=ACCESS_TOKEN, access_token_secret=ACCESS_TOKEN_SECRET)\n",
    "\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df233bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = []\n",
    "\n",
    "def save_list(vehicle_type, url_list):\n",
    "    jsonString = json.dumps(url_list)\n",
    "    path = \"./dataset/\" + vehicle_type + \"/img_urls.json\"\n",
    "    jsonFile = open(path, \"w\")\n",
    "    jsonFile.write(jsonString)\n",
    "    jsonFile.close()\n",
    "    \n",
    "\n",
    "def read_list(vehicle_type: str):\n",
    "    path = \"./dataset/\" + vehicle_type + \"/img_urls.json\"\n",
    "    fileObject = open(path, \"r\")\n",
    "    jsonContent = fileObject.read()\n",
    "    try:\n",
    "        url_list = json.loads(jsonContent)\n",
    "    except:\n",
    "        #json is empty\n",
    "        url_list = []\n",
    "        pass\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users of interest: UAWeapons, OSINTua, RALee85, praisethesteph, 200_zoka, oryxspioenkop, Arslon_Xudosi\n",
    "# from:twitterdev\n",
    "# query_t72 = 'T-72 has:images -is:retweet (lang:en OR lang:ru OR lang:uk)'\n",
    "# query_mtlb = '(MT-LB OR MT-LBV OR MT-LBVM OR MT-LBVMK OR MT-LBVM/K) -is:retweet from:UAWeapons'\n",
    "\n",
    "query_vehicle_list = [  # (model,query content)\n",
    "    ('MT-LB','MT-LB OR MT-LBV OR MT-LBVM OR MT-LBVMK OR MT-LBVM/K OR MT-LBu'),\n",
    "    ('BTR-80','BTR-80 OR BTR-82'),\n",
    "    ('BTR-82A','BTR-80A OR BTR-82A'),\n",
    "    ('BMP-1','BMP-1'),\n",
    "    ('BMP-2','BMP-2'),\n",
    "    ('BMP-3','BMP-3 OR BMP-3M'),\n",
    "    ('T-64','T-64 OR T-64A OR T-64B OR T-64BV OR T-64B1M OR T-64BM OR T-64BM2'),\n",
    "    ('T-72','T-72 OR T-72A OR T-72AV OR T-72AMT OR T-72B OR T-72BA OR T-72B3 OR T-72B3 OR T-72M OR T-72M1'),\n",
    "    ('T-80','T-80 OR T-80B OR T-80BV OR T-80U OR T-80BVM'),\n",
    "    ('T-90','T-90 OR T-90A OR T-90M'),\n",
    "    ('2S1','2S1 OR Gvozdika'),\n",
    "    ('2S3','2S3 OR Akatsiya'),\n",
    "    ('2S19','2S19 OR 2S19M OR 2S19M1 OR 2S19M2 OR Msta OR Msta-S OR Msta-SM2'),\n",
    "    ('BM-21','BM-21'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1919c78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for vehicle in query_vehicle_list:\n",
    "    model, query_content = vehicle\n",
    "    \n",
    "    url_counter = 0\n",
    "    url_list = []\n",
    "    url_list = read_list(model)\n",
    "    \n",
    "    query = '(' + query_content + ') (russian OR ukrainian OR ukraine OR russia OR army OR captured OR kherson OR kharkiv OR oblast OR donetsk OR severodonetsk OR luhansk OR lugansk OR Dnieper OR Dnipro OR izium OR izyum) has:images -is:retweet'\n",
    "    #print(query)\n",
    "\n",
    "    paginator = tweepy.Paginator(client.search_recent_tweets, query=query, max_results=100, limit=1000, expansions=['attachments.media_keys'], media_fields=['url'])\n",
    "    for page in paginator:\n",
    "        #print(page.includes['media'])  \n",
    "        for item in page.includes['media']:\n",
    "            url_list.append(item.url)\n",
    "            url_counter += 1\n",
    "\n",
    "    save_list(model)\n",
    "    print('Saved', url_counter, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e7c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/70854869/tweepy-problem-retrieving-username-informations-with-twitter-v2-api\n",
    "#https://stackoverflow.com/questions/72016766/tweepy-only-lets-me-get-100-results-how-do-i-get-more-ive-read-about-paginati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a50510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function deletes all duplicate URLs by turning List into a Set.\n",
    "def remove_duplicates(vehicle_type):\n",
    "    url_list = []\n",
    "    url_list = read_list(vehicle_type)\n",
    "    \n",
    "    initial_amount = len(url_list)\n",
    "    url_list = list(set(url_list))\n",
    "    final_amount = len(url_list)\n",
    "\n",
    "    save_list(vehicle_type, url_list)\n",
    "    print(vehicle_type, '-', initial_amount - final_amount, 'duplicated URLs deleted.')\n",
    "\n",
    "#remove_duplicates('2S3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73669d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Function gets all of the links from the Oryx's .csv file that correspond to a vehicle of interest\n",
    "def csv_lookup(vehicle_type):\n",
    "    counter = 0\n",
    "\n",
    "    url_list = []\n",
    "    url_list = read_list(vehicle_type)\n",
    "\n",
    "    with open('./dataset/totals_by_system.csv', newline='') as csvfile:\n",
    "        csv_reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in csv_reader:\n",
    "            #Can't do list unpacking for some reason, so I have to do it this way\n",
    "            system = row[2]\n",
    "            status = row[3]\n",
    "            url = row[4]\n",
    "\n",
    "            if vehicle_type in system:\n",
    "                counter += 1\n",
    "                url_list.append(url)\n",
    "\n",
    "    save_list(vehicle_type, url_list)\n",
    "    print('Added', counter, vehicle_type, 'URLs to the list. Total number:', len(url_list))\n",
    "\n",
    "for item in query_vehicle_list:\n",
    "    vehicle_type, _ = item\n",
    "    csv_lookup(vehicle_type)\n",
    "    remove_duplicates(vehicle_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cbb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Function that counts the amount of .jpg inside a directory. Since the function download_img now assigns names using the very same URL, this function will not be used.\n",
    "def count_img(vehicle_type):\n",
    "    counter = 0\n",
    "    folder_path = './dataset/' + vehicle_type\n",
    "    for path in os.scandir(folder_path):\n",
    "        if path.is_file():\n",
    "            if path.name[-4:] == '.jpg':\n",
    "                counter += 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import urllib.request\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# Function downloads images from URLs and assigns them the original name from the same URL. It's done this way in order to prevent downloading the same image twice.\n",
    "def download_img(url, vehicle_type):\n",
    "    if url is not None:\n",
    "        if 'https://twitter.com/' not in url:\n",
    "            file_name_temp = url.split('/')\n",
    "            if 'pbs.twimg.com/media/' in url: # In case the URL is a regular Twitter image\n",
    "                file_name = file_name_temp[-1]\n",
    "            else: # In case the URL is something like 'i.postimg.cc/NFwX6m7d/763.png'\n",
    "                file_name = file_name_temp[-2] + file_name_temp[-1]\n",
    "            full_path = './dataset/' + vehicle_type + '/' + file_name\n",
    "            if not os.path.exists(full_path):\n",
    "                #urllib.request.urlretrieve(url, full_path)\n",
    "                r = requests.get(url)  \n",
    "                with open(full_path, 'wb') as f:\n",
    "                    f.write(r.content)\n",
    "                return 'Downloaded'\n",
    "            else:\n",
    "                # Picture already exists\n",
    "                return 'Exists'\n",
    "        else:\n",
    "            # URL belongs to a Twitter video\n",
    "            return 'Video'\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "for item in query_vehicle_list:\n",
    "    counter_downloaded = 0\n",
    "    counter_pic_exists = 0\n",
    "    counter_tw_videos = 0\n",
    "\n",
    "    vehicle_type, _ = item\n",
    "    remove_duplicates(vehicle_type)\n",
    "    url_list = read_list(vehicle_type)\n",
    "    print('+ Out of', len(url_list), vehicle_type, 'URLs:')\n",
    "    for url in url_list:\n",
    "        outcome = download_img(url, vehicle_type)\n",
    "        if outcome == 'Downloaded': # Downloaded successfully\n",
    "            counter_downloaded += 1\n",
    "        elif outcome == 'Exists':   # Picture already exists\n",
    "            counter_pic_exists += 1\n",
    "        else: # outcome == 'Video': - Link belongs to a Twitter video\n",
    "            counter_tw_videos += 1\n",
    "\n",
    "    print('   -', counter_downloaded, 'new pictures were downloaded')\n",
    "    print('   -', counter_pic_exists, 'pictures already existed')\n",
    "    print('   -', counter_tw_videos, 'URLs belonged to Twitter videos')\n",
    "\n",
    "#download_img('https://twitter.com/UAWeapons/status/1564984095591088129','2S3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "79ae438818e454af4f26ac53bc90cc6114af98306db0d7e90db8f6b9a9700471"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
